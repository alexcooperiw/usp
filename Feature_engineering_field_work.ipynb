{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Field work - feature engineering\n",
    "\n",
    "In this field work, you will create new features based on the primary layer of your data asset.\n",
    "\n",
    "#### Instructions\n",
    "* We ask you to create **3 features** from various tables\n",
    "* Once a feature is calculated, select a suitable visualization and/or descriptive analysis and note down any insights you will have about the feature\n",
    "* For each feature, we provide hints which tables and fields are required\n",
    "* The introductory section of the code accesses all required tables from the data asset\n",
    "* Don't forget to import any additional packages you might require (e.g., matplotlib, pandas, pyspark, ...)\n",
    "* Within each exercise, use multiple cells to keep your code modular\n",
    "\n",
    "## Accessing tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] =\"/usr/lib/jvm/java-8-openjdk-amd64/\"\n",
    "os.environ[\"SPARK_VERSION\"] =\"2.4.0\"\n",
    "os.environ[\"SPARK_FOLDER\"] =\"/opt/spark\"\n",
    "os.environ[\"SPARK_HOME\"] =\"/opt/spark/spark-2.4.0-bin-without-hadoop\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] =\"ipython3\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] =\"/usr/bin/python3\"\n",
    "os.environ[\"SPARK_DIST_CLASSPATH\"] =\"/opt/spark/hadoop-3.1.1/etc/hadoop:/opt/spark/hadoop-3.1.1/share/hadoop/common/lib/*:/opt/spark/hadoop-3.1.1/share/hadoop/common/*:/opt/spark/hadoop3.1.1/share/hadoop/hdfs:/opt/spark/hadoop-3.1.1/share/hadoop/hdfs/lib/*:/opt/spark/hadoop-3.1.1/share/hadoop/hdfs/*:/opt/spark/hadoop-3.1.1/share/hadoop/mapreduce/lib/*:/opt/spark/hadoop-3.1.1/share/hadoop/mapreduce/*:/opt/spark/hadoop-3.1.1/share/hadoop/yarn:/opt/spark/hadoop-3.1.1/share/hadoop/yarn/lib/*:/opt/spark/hadoop-3.1.1/share/hadoop/yarn/*:/opt/spark/hadoop-3.1.1/share/hadoop/tools/lib/*\"\n",
    "os.environ[\"PATH\"] = os.environ[\"SPARK_HOME\"]+\"/bin:\"+os.environ[\"PATH\"]\n",
    "\n",
    "print(os.environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Kedro context of the data asset\n",
    "import logging\n",
    "from kedro.context import load_context\n",
    "# TASK: Update path where you have imported the repo from bitbucket\n",
    "context = load_context(\"/home/akhil_kulkarni/unicorn/supply_chain_data_asset/\")\n",
    "catalog = context.catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all tables included in the data catalogue\n",
    "catalog.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all required tables through kedro, using the data catalog\n",
    "pri_product = context.catalog.load(\"pri_product\")\n",
    "pri_product_hierarchy = context.catalog.load(\"pri_product_hierarchy\")\n",
    "pri_product_location_behavior = context.catalog.load(\"pri_product_location_behavior\")\n",
    "pri_location = context.catalog.load(\"pri_location\")\n",
    "pri_duns_master = context.catalog.load(\"pri_duns_master\")\n",
    "pri_usp_midas = context.catalog.load(\"pri_usp_midas\")\n",
    "\n",
    "pri_product.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. For each ingredient, calculate the number of countries where it is manufactured\n",
    "### Create feature\n",
    "Hints:\n",
    "\n",
    "Join table *pri_product* with *pri_product_location_behavior* and filter for behaviors which count as manufacturing ('API MANUF' and 'MANUF'). Join the table via the 'location' with table *pri_location* to add the country information. Aggregate by ingrediet and count the number of distinct countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore feature\n",
    "Explore the new feature by performing an appropriate visualization and/or descriptive analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note down any insights gained from the analyses below (e.g., findings, potential alternative representations for the feature, additional cleaning improvements, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Do same as #1, but for a Finished product's ingredients \n",
    "Hints:\n",
    "for each finished product, get a list of active ingredients by joining pri_product* with *pri_product_hierarchy*.\n",
    "For all these ingredients, find number of countries manufacturing those ingredients. \n",
    "\n",
    "For example: Let's say Product P1 has Ingredients I1, I2 and I3. I1 is made in China and India, I2 in China and Italy, and I3 in Italy and India, then Product P1 should have the count 3 for countries manufacturing it's ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore feature\n",
    "Explore the new feature by performing an appropriate visualization and/or descriptive analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note down any insights gained from the analyses below (e.g., findings, potential alternative representations for the feature, additional cleaning improvements, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For each ingredient, calculate the percentage of manufacturing sites that have had an FDA warning letter.\n",
    "Hints:\n",
    "get list of sites manufacturing an ingredient by joining *pri_product* with *pri_product_location_behavior*. Check how many of those locations have \"HAS_FDA_WARNING\" behavior in the behavior table. \n",
    "\n",
    "For example, if Ingredient I1 his manufactured in 10 locations, and 2 of those locations has an FDA warning letter, 20% of sites manufacturing I1 have had FDA warning letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore feature\n",
    "Explore the new feature by performing an appropriate visualization and/or descriptive analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note down any insights gained from the analyses below (e.g., findings, potential alternative representations for the feature, additional cleaning improvements, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
